{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:42:05.829678Z",
     "start_time": "2023-10-20T20:42:03.840507Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "peft_model_id = \"dlwh/levanter-lora-test\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map=\"auto\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# if on macos, set cpu b/c mps doesn't work yet w/ int64.cumsum\n",
    "if model.device.type == \"mps\":\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'<|endoftext|>'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:41:30.191878Z",
     "start_time": "2023-10-20T20:41:30.187778Z"
    }
   },
   "id": "221a621e5ffc7dfa"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  818, 17219,    11,   262,  3632,   318,   262,  3632,   338,  4165,\n",
      "          2723,   286,  1321,    13,   383,  3632,   318,   262,  3632,   338,\n",
      "          4165,  2723,   286,  1321,    13,   198,   198,   464,  3632,   318,\n",
      "           262,  3632,   338,  4165,  2723,   286,  1321,    13,   383,  3632]])\n",
      "[\"In biology, the brain is the brain's primary source of information. The brain is the brain's primary source of information.\\n\\nThe brain is the brain's primary source of information. The brain\"]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "inputs = tokenizer(\"In biology,\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # outputs = model.greedy_search(**inputs, max_new_tokens=20, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "    config = GenerationConfig(output_scores=True, return_dict_in_generate=True)\n",
    "    result = model.generate(**inputs, generation_config=config, max_length=40, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "    outputs = result.sequences\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T21:08:53.037311Z",
     "start_time": "2023-10-20T21:08:52.211354Z"
    }
   },
   "id": "8eb50bac5e8041b8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[(tensor(-83.2557), tensor(-85.8009)),\n (tensor(-84.2175), tensor(-77.1657)),\n (tensor(-86.4178), tensor(-77.3928)),\n (tensor(-110.7105), tensor(-96.9994)),\n (tensor(-112.1313), tensor(-99.4627)),\n (tensor(-70.8388), tensor(-66.0480)),\n (tensor(-116.3585), tensor(-109.1837)),\n (tensor(-126.5522), tensor(-114.2512)),\n (tensor(-21.2022), tensor(-17.7173)),\n (tensor(-112.0298), tensor(-103.6370)),\n (tensor(-83.9326), tensor(-80.3852)),\n (tensor(-156.5771), tensor(-159.3918)),\n (tensor(-98.5236), tensor(-87.6358)),\n (tensor(-93.9978), tensor(-89.0802)),\n (tensor(-119.0411), tensor(-114.5944)),\n (tensor(-117.6953), tensor(-103.9253)),\n (tensor(-33.1703), tensor(-27.5888)),\n (tensor(-119.7291), tensor(-112.0733)),\n (tensor(-116.8803), tensor(-104.8546)),\n (tensor(-107.4814), tensor(-104.0858)),\n (tensor(-108.6564), tensor(-101.9731)),\n (tensor(-58.9992), tensor(-57.9402)),\n (tensor(-117.3935), tensor(-121.8353)),\n (tensor(-255.6712), tensor(-268.7751)),\n (tensor(-126.3036), tensor(-120.7409)),\n (tensor(-92.9861), tensor(-88.1759)),\n (tensor(-81.6440), tensor(-76.6083)),\n (tensor(-103.5917), tensor(-103.0732)),\n (tensor(-102.5509), tensor(-88.3797)),\n (tensor(134.5594), tensor(139.3893)),\n (tensor(-44.6517), tensor(-39.0135)),\n (tensor(38.3891), tensor(48.4450)),\n (tensor(-253.1624), tensor(-252.0663)),\n (tensor(86.2598), tensor(89.8133)),\n (tensor(113.5913), tensor(110.7711)),\n (tensor(-93.1449), tensor(-96.1423)),\n (tensor(-95.0637), tensor(-86.2624))]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(s[0][tokenizer.eos_token_id], s[0][t]) for s,t in zip(result.scores, result.sequences[0])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T21:08:54.434562Z",
     "start_time": "2023-10-20T21:08:54.419320Z"
    }
   },
   "id": "7479cb735718a26b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  818, 17219,    11,   262,  3632,   318,   262,  3632,   338,  4165,\n",
      "          2723,   286,  1321,    13,   383,  3632,   318,   262,  3632,   338]])\n",
      "[\"In biology, the brain is the brain's primary source of information. The brain is the brain's\"]\n"
     ]
    }
   ],
   "source": [
    "orig_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "orig_model.eval()\n",
    "\n",
    "if orig_model.device.type == \"mps\":\n",
    "    orig_model.cpu()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs = orig_model.generate(**inputs, max_length=20, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:49:52.684619Z",
     "start_time": "2023-10-20T20:49:51.054806Z"
    }
   },
   "id": "2330f87eb1ced862"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = model.state_dict()\n",
    "\n",
    "d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T20:41:17.567963Z"
    }
   },
   "id": "a52af00e3f6b1980"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k, v in d.items(): \n",
    "    if \"lora\" in k:\n",
    "        print(k, v.norm())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T20:41:17.568724Z"
    }
   },
   "id": "6fa16cc2a82dc8cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
