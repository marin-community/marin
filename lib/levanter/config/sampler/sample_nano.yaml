hf_checkpoint: "meta-llama/Llama-3.2-1B"
tokenizer: "meta-llama/Llama-3.2-1B"
trainer:
  ray:
    auto_start_cluster: false
  mp: p=bfloat16,c=bfloat16
  tensor_parallel_axes: ["mlp", "heads", "kv_head", "vocab"]
  model_axis_size: 1

prompts:
  - "Four score and seven years ago, our"
  # - "On the first day of Christmas, my true love gave to me",
  - "In a hole in the ground there lived a hobbit, not a nasty, dirty, wet hole"

max_new_tokens: 32

engine:
  max_pages: 256
  max_seqs: 8
  page_size: 8
  max_pages_per_seq: 16
  max_queued_tokens: 16
  max_seqs_in_prefill: 8
  max_prefill_size: 128
  max_tokens_per_round: 8
  max_rounds: 16
