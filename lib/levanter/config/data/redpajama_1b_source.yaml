tokenizer: EleutherAI/gpt-neox-20b
cache_dir: gs://levanter-data/tokenized
components:
  redpajama_1b:
    source:
      type: hf
      id: togethercomputer/RedPajama-Data-1T-Sample
      splits:
        - train
    cache_dir: gs://levanter-data/tokenized/redpajama-sample/
