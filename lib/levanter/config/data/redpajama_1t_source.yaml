tokenizer: EleutherAI/gpt-neox-20b
cache_dir: gs://levanter-data/tokenized
components:
  redpajama_1t:
    source:
      type: hf
      id: togethercomputer/RedPajama-Data-1T
      splits:
        - train
    cache_dir: gs://levanter-data/tokenized/redpajama/
