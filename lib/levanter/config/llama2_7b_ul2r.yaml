data:
  tokenizer: ./llama_2_7b_hf_ul2r/
  configs:
    pile:
      id: dlwh/wikitext_103_detokenized
      cache_dir: /tmp/marin_cache_pile
    ul2r:
      id: dlwh/wikitext_103_detokenized
      cache_dir: /tmp/marin_cache_ul2r
      format:
        type: ul2r
        task_configs:
          r:
            type: rx
            mask_prob: 0.15
            mean_span_length: 3.0
            random_roll: true
            task_token_id: 32000
          x1:
            type: rx
            mask_prob: 0.15
            mean_span_length: 32.0
            random_roll: true
            task_token_id: 32001
          x2:
            type: rx
            mask_prob: 0.5
            mean_span_length: 3.0
            random_roll: true
            task_token_id: 32001
          s:
            type: s
            task_token_id: 32002
        task_probs:
          r: 0.5
          x1: 0.125
          x2: 0.125
          s: 0.25
        rng_seed: 42
        sentinel_token_id_start: 32003
        sentinel_token_id_count: 100
  train_weights:
    pile: 0 # only use Pile for evaluation; UL2R says loss should decrease
    ul2r: 1

model:
  type: llama
initialize_from_hf: true
use_hf_model_config: true

# From config/llam2_7b_continued.yaml

trainer:
  tracker:
    type: wandb
    project: "levanter"
    tags: ["ul2r", "llama2"]

  mp: p=f32,c=bfloat16

  model_axis_size: 1
  per_device_eval_parallelism: 4

  train_batch_size: 1024
  num_train_steps: 10000
  steps_per_eval: 500

optimizer:
  learning_rate: 1.2e-4
  weight_decay: 0.0
