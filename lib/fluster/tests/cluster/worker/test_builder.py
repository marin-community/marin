# Copyright 2025 The Marin Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for VenvCache and ImageBuilder."""

import asyncio
import shutil
import subprocess

import pytest

from fluster.cluster.worker.builder import ImageBuilder, VenvCache


@pytest.fixture
def temp_cache_dir(tmp_path):
    """Create a temporary cache directory."""
    cache_dir = tmp_path / "cache"
    uv_cache_dir = tmp_path / "uv_cache"
    cache_dir.mkdir()
    uv_cache_dir.mkdir()
    return cache_dir, uv_cache_dir


@pytest.fixture
def test_bundle(tmp_path):
    """Create a test bundle with pyproject.toml and uv.lock."""
    bundle_dir = tmp_path / "test_bundle"
    bundle_dir.mkdir()

    # Create minimal pyproject.toml
    pyproject = """[project]
name = "test-package"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
"""
    (bundle_dir / "pyproject.toml").write_text(pyproject)

    # Create uv.lock file
    # This is a minimal lock file - in real usage it would be generated by uv
    uv_lock = """version = 1
requires-python = ">=3.11"

[[package]]
name = "test-package"
version = "0.1.0"
source = { editable = "." }
"""
    (bundle_dir / "uv.lock").write_text(uv_lock)

    return bundle_dir


@pytest.fixture
def test_bundle_with_deps(tmp_path):
    """Create a test bundle with actual dependencies for real uv testing."""
    bundle_dir = tmp_path / "test_bundle_deps"
    bundle_dir.mkdir()

    # Create package directory structure
    src_dir = bundle_dir / "src" / "test_package"
    src_dir.mkdir(parents=True)
    (src_dir / "__init__.py").write_text("# Test package\n")

    # Create pyproject.toml with a simple dependency
    pyproject = """[project]
name = "test-package"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "httpx>=0.28.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/test_package"]
"""
    (bundle_dir / "pyproject.toml").write_text(pyproject)

    # Run uv lock to generate real lock file
    try:
        subprocess.run(
            ["uv", "lock"],
            cwd=bundle_dir,
            check=True,
            capture_output=True,
        )
    except (subprocess.CalledProcessError, FileNotFoundError):
        pytest.skip("uv not available or failed to create lock file")

    return bundle_dir


@pytest.mark.asyncio
async def test_compute_deps_hash(temp_cache_dir, test_bundle):
    """Test that deps hash is computed from pyproject.toml and uv.lock."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    hash1 = cache.compute_deps_hash(test_bundle)

    # Should be consistent
    hash2 = cache.compute_deps_hash(test_bundle)
    assert hash1 == hash2

    # Modify pyproject.toml
    (test_bundle / "pyproject.toml").write_text("[project]\nname = 'changed'\n")
    hash3 = cache.compute_deps_hash(test_bundle)

    # Hash should change
    assert hash3 != hash1


@pytest.mark.asyncio
async def test_get_cache_miss(temp_cache_dir, test_bundle):
    """Test that get returns None for cache miss."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    deps_hash = cache.compute_deps_hash(test_bundle)
    result = cache.get(deps_hash)

    assert result is None


@pytest.mark.asyncio
async def test_get_cache_hit(temp_cache_dir, test_bundle):
    """Test that get returns archive path and updates mtime."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    deps_hash = cache.compute_deps_hash(test_bundle)

    # Create a fake archive
    archive_path = cache._cache_dir / f"{deps_hash}.tar.zst"
    archive_path.write_bytes(b"fake archive")

    # Get original mtime
    original_mtime = archive_path.stat().st_mtime

    # Wait a bit to ensure mtime difference
    await asyncio.sleep(0.01)

    # Get from cache
    result = cache.get(deps_hash)

    assert result == archive_path
    assert result.exists()

    # Mtime should be updated
    new_mtime = archive_path.stat().st_mtime
    assert new_mtime >= original_mtime


@pytest.mark.asyncio
async def test_archive_and_extract(temp_cache_dir, test_bundle):
    """Test archiving and extracting a venv."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    # Create a fake venv directory
    venv_path = test_bundle / ".venv"
    venv_path.mkdir()
    (venv_path / "test_file.txt").write_text("test content")

    # Archive it
    deps_hash = "test_hash_123"
    await cache._archive_venv(venv_path, deps_hash)

    # Check archive exists
    archive_path = cache._cache_dir / f"{deps_hash}.tar.zst"
    assert archive_path.exists()

    # Remove original venv
    shutil.rmtree(venv_path)
    assert not venv_path.exists()

    # Extract to new location
    target_bundle = temp_cache_dir[0] / "target"
    target_bundle.mkdir()
    extracted_path = await cache._extract_venv(archive_path, target_bundle)

    # Verify extraction
    assert extracted_path == target_bundle / ".venv"
    assert extracted_path.exists()
    assert (extracted_path / "test_file.txt").exists()
    assert (extracted_path / "test_file.txt").read_text() == "test content"


@pytest.mark.asyncio
async def test_lru_eviction(temp_cache_dir, test_bundle):
    """Test LRU eviction removes oldest archives."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir, max_entries=2)

    # Create 3 fake archives with different times
    archives = []
    for i in range(3):
        archive = cache._cache_dir / f"hash_{i}.tar.zst"
        archive.write_bytes(b"fake")
        archives.append(archive)

        # Wait to ensure different mtimes
        await asyncio.sleep(0.01)

    # All exist initially
    assert all(a.exists() for a in archives)

    # Trigger eviction
    await cache._evict_lru()

    # Oldest should be removed, newest 2 should remain
    assert not archives[0].exists(), "Oldest archive should be evicted"
    assert archives[1].exists(), "Second archive should remain"
    assert archives[2].exists(), "Newest archive should remain"


@pytest.mark.asyncio
async def test_ensure_permissions(temp_cache_dir):
    """Test ensure_permissions sets correct ownership."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    # Create some files in uv cache
    test_file = uv_cache_dir / "test.txt"
    test_file.write_text("test")

    subdir = uv_cache_dir / "subdir"
    subdir.mkdir()
    (subdir / "file.txt").write_text("test")

    # Try to set permissions (may fail if not running as root)
    # This test verifies the method runs without error
    try:
        cache.ensure_permissions(uid=1000, gid=1000)
    except PermissionError:
        # Expected on systems where we can't change ownership
        pass


@pytest.mark.asyncio
@pytest.mark.slow
async def test_build_venv_real(temp_cache_dir, test_bundle_with_deps):
    """Test building a real venv with uv sync.

    This test requires uv to be installed and is marked as slow.
    """
    # Check if uv is available
    try:
        subprocess.run(["uv", "--version"], check=True, capture_output=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        pytest.skip("uv not available")

    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    # Build venv
    venv_path, deps_hash = await cache.build_venv(test_bundle_with_deps, extras=[])

    # Verify venv exists
    assert venv_path.exists()
    assert venv_path.is_dir()
    assert (venv_path / "pyvenv.cfg").exists()

    # Verify archive was created
    archive_path = cache._cache_dir / f"{deps_hash}.tar.zst"
    assert archive_path.exists()

    # Remove venv and build again - should use cache
    shutil.rmtree(venv_path)
    assert not venv_path.exists()

    venv_path2, deps_hash2 = await cache.build_venv(test_bundle_with_deps, extras=[])

    # Should have same hash and venv should be restored from cache
    assert deps_hash2 == deps_hash
    assert venv_path2.exists()
    assert (venv_path2 / "pyvenv.cfg").exists()


@pytest.mark.asyncio
@pytest.mark.slow
async def test_shared_uv_cache_speeds_up_builds(temp_cache_dir, tmp_path):
    """Test that shared UV cache speeds up subsequent builds.

    This test verifies the shared UV cache benefit by building two bundles
    with the same dependency and checking the UV cache is populated.
    """
    # Check if uv is available
    try:
        subprocess.run(["uv", "--version"], check=True, capture_output=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        pytest.skip("uv not available")

    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    # Create two bundles with the same dependency
    bundles = []
    for i in range(2):
        bundle_dir = tmp_path / f"bundle_{i}"
        bundle_dir.mkdir()

        # Create package directory structure
        src_dir = bundle_dir / "src" / f"test_package_{i}"
        src_dir.mkdir(parents=True)
        (src_dir / "__init__.py").write_text("# Test package\n")

        pyproject = f"""[project]
name = "test-package-{i}"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "httpx>=0.28.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/test_package_{i}"]
"""
        (bundle_dir / "pyproject.toml").write_text(pyproject)

        # Generate lock file
        subprocess.run(["uv", "lock"], cwd=bundle_dir, check=True, capture_output=True)
        bundles.append(bundle_dir)

    # Build first venv
    await cache.build_venv(bundles[0], extras=[])

    # UV cache should now contain wheels
    uv_cache_contents = list(uv_cache_dir.rglob("*"))
    assert len(uv_cache_contents) > 0, "UV cache should be populated after first build"

    # Build second venv - should reuse wheels from UV cache
    await cache.build_venv(bundles[1], extras=[])

    # Both venvs should exist
    assert (bundles[0] / ".venv").exists()
    assert (bundles[1] / ".venv").exists()


@pytest.mark.asyncio
async def test_build_venv_with_extras(temp_cache_dir, test_bundle):
    """Test that extras are passed correctly to uv sync."""
    cache_dir, uv_cache_dir = temp_cache_dir
    cache = VenvCache(cache_dir, uv_cache_dir)

    # Add extras to pyproject
    pyproject = """[project]
name = "test-package"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[project.optional-dependencies]
dev = []
test = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
"""
    (test_bundle / "pyproject.toml").write_text(pyproject)

    # Create lock file
    (test_bundle / "uv.lock").write_text("version = 1\nrequires-python = '>=3.11'\n")

    # Mock _run_uv_sync to capture the command
    captured_cmd = []

    async def mock_run(_bundle_path, extras):
        # Just record what would be called
        captured_cmd.append(extras)
        # Don't actually run uv
        raise RuntimeError("Mocked")

    cache._run_uv_sync = mock_run

    try:
        await cache.build_venv(test_bundle, extras=["dev", "test"])
    except RuntimeError:
        pass  # Expected from mock

    # Verify extras were passed
    assert captured_cmd == [["dev", "test"]]


# ImageBuilder Tests


@pytest.fixture
def docker_bundle(tmp_path):
    """Create a minimal test bundle for Docker builds."""
    bundle_dir = tmp_path / "docker_bundle"
    bundle_dir.mkdir()

    # Create package directory structure
    src_dir = bundle_dir / "src" / "test_app"
    src_dir.mkdir(parents=True)
    (src_dir / "__init__.py").write_text('"""Test app."""\n')
    (src_dir / "main.py").write_text(
        'def main():\n    print("Hello from Docker!")\n\nif __name__ == "__main__":\n    main()\n'
    )

    # Create pyproject.toml
    pyproject = """[project]
name = "test-app"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/test_app"]
"""
    (bundle_dir / "pyproject.toml").write_text(pyproject)

    # Create uv.lock
    uv_lock = """version = 1
requires-python = ">=3.11"

[[package]]
name = "test-app"
version = "0.1.0"
source = { editable = "." }
"""
    (bundle_dir / "uv.lock").write_text(uv_lock)

    return bundle_dir


def check_docker_available():
    """Check if Docker is available and running."""
    try:
        result = subprocess.run(
            ["docker", "info"],
            check=True,
            capture_output=True,
            timeout=5,
        )
        return result.returncode == 0
    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        return False


@pytest.mark.asyncio
@pytest.mark.slow
async def test_image_builder_initialization(tmp_path):
    """Test ImageBuilder initialization creates cache directory."""
    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000", max_images=10)

    assert builder._cache_dir == cache_dir / "images"
    assert builder._registry == "localhost:5000"
    assert builder._max_images == 10
    assert builder._cache_dir.exists()


@pytest.mark.asyncio
@pytest.mark.slow
async def test_image_exists_returns_false_for_missing_image(tmp_path):
    """Test _image_exists returns False for non-existent image."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    exists = await builder._image_exists("nonexistent:tag")
    assert exists is False


@pytest.mark.asyncio
@pytest.mark.slow
async def test_content_addressed_image_tags(tmp_path, docker_bundle):
    """Test that ImageBuilder generates content-addressed image tags."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    job_id = "test-job-123"
    deps_hash = "abcdef1234567890"
    base_image = "python:3.11-slim"

    # Build image
    result = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash,
    )

    # Verify content-addressed tag format
    expected_tag = f"localhost:5000/fluster-job-{job_id}:{deps_hash[:8]}"
    assert result.image_tag == expected_tag
    assert result.deps_hash == deps_hash
    assert result.from_cache is False
    assert result.build_time_ms > 0

    # Verify image exists
    exists = await builder._image_exists(expected_tag)
    assert exists is True

    # Cleanup
    await asyncio.create_subprocess_exec("docker", "rmi", expected_tag, stdout=subprocess.DEVNULL)


@pytest.mark.asyncio
@pytest.mark.slow
async def test_image_caching(tmp_path, docker_bundle):
    """Test that subsequent builds with same deps_hash use cached image."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    job_id = "cache-test-456"
    deps_hash = "cachedep1234567890"
    base_image = "python:3.11-slim"

    # First build - not from cache
    result1 = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash,
    )

    assert result1.from_cache is False
    assert result1.build_time_ms > 0

    # Second build - should be from cache
    result2 = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash,
    )

    assert result2.from_cache is True
    assert result2.build_time_ms == 0
    assert result2.image_tag == result1.image_tag

    # Cleanup
    await asyncio.create_subprocess_exec("docker", "rmi", result1.image_tag, stdout=subprocess.DEVNULL)


@pytest.mark.asyncio
@pytest.mark.slow
async def test_deps_hash_change_triggers_rebuild(tmp_path, docker_bundle):
    """Test that changing deps_hash triggers a rebuild."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    job_id = "rebuild-test-789"
    base_image = "python:3.11-slim"

    # Build with first deps_hash
    deps_hash1 = "oldhash1234567890"
    result1 = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash1,
    )

    assert result1.from_cache is False
    expected_tag1 = f"localhost:5000/fluster-job-{job_id}:{deps_hash1[:8]}"
    assert result1.image_tag == expected_tag1

    # Build with different deps_hash - should rebuild
    deps_hash2 = "newhash0987654321"
    result2 = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash2,
    )

    assert result2.from_cache is False
    expected_tag2 = f"localhost:5000/fluster-job-{job_id}:{deps_hash2[:8]}"
    assert result2.image_tag == expected_tag2
    assert result2.image_tag != result1.image_tag

    # Both images should exist
    exists1 = await builder._image_exists(expected_tag1)
    exists2 = await builder._image_exists(expected_tag2)
    assert exists1 is True
    assert exists2 is True

    # Cleanup
    await asyncio.create_subprocess_exec("docker", "rmi", expected_tag1, stdout=subprocess.DEVNULL)
    await asyncio.create_subprocess_exec("docker", "rmi", expected_tag2, stdout=subprocess.DEVNULL)


@pytest.mark.asyncio
@pytest.mark.slow
async def test_buildkit_cache_mounts(tmp_path, docker_bundle):
    """Test that BuildKit cache mounts are used for UV cache."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    # Verify DOCKER_BUILDKIT is set in environment during build
    job_id = "buildkit-test-abc"
    deps_hash = "buildkit1234567890"
    base_image = "python:3.11-slim"

    # Build image - BuildKit should be enabled
    result = await builder.build(
        bundle_path=docker_bundle,
        base_image=base_image,
        extras=[],
        job_id=job_id,
        deps_hash=deps_hash,
    )

    # Verify image was built (BuildKit enabled by default in _docker_build)
    assert result.from_cache is False
    exists = await builder._image_exists(result.image_tag)
    assert exists is True

    # Cleanup
    await asyncio.create_subprocess_exec("docker", "rmi", result.image_tag, stdout=subprocess.DEVNULL)


@pytest.mark.asyncio
@pytest.mark.slow
async def test_image_build_with_extras(tmp_path):
    """Test building image with extras."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    # Create bundle with extras
    bundle_dir = tmp_path / "extras_bundle"
    bundle_dir.mkdir()

    src_dir = bundle_dir / "src" / "test_app"
    src_dir.mkdir(parents=True)
    (src_dir / "__init__.py").write_text('"""Test app."""\n')

    pyproject = """[project]
name = "test-app"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[project.optional-dependencies]
dev = []
test = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/test_app"]
"""
    (bundle_dir / "pyproject.toml").write_text(pyproject)

    # Generate proper lock file
    try:
        subprocess.run(
            ["uv", "lock"],
            cwd=bundle_dir,
            check=True,
            capture_output=True,
        )
    except (subprocess.CalledProcessError, FileNotFoundError):
        pytest.skip("uv not available or failed to create lock file")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000")

    # Build with extras
    result = await builder.build(
        bundle_path=bundle_dir,
        base_image="python:3.11-slim",
        extras=["dev", "test"],
        job_id="extras-test",
        deps_hash="extrahash123",
    )

    assert result.from_cache is False

    # Cleanup
    await asyncio.create_subprocess_exec("docker", "rmi", result.image_tag, stdout=subprocess.DEVNULL)


@pytest.mark.asyncio
@pytest.mark.slow
async def test_lru_eviction_of_images(tmp_path, docker_bundle):
    """Test LRU eviction removes old images when over limit."""
    if not check_docker_available():
        pytest.skip("Docker not available")

    cache_dir = tmp_path / "cache"
    builder = ImageBuilder(cache_dir, registry="localhost:5000", max_images=2)

    base_image = "python:3.11-slim"
    images_built = []

    # Build 3 images to trigger eviction
    for i in range(3):
        result = await builder.build(
            bundle_path=docker_bundle,
            base_image=base_image,
            extras=[],
            job_id=f"eviction-test-{i}",
            deps_hash=f"evict{i:016d}",
        )
        images_built.append(result.image_tag)

        # Small delay to ensure different creation times
        await asyncio.sleep(0.1)

    # After building 3 images with max_images=2, oldest should be evicted
    # Note: _evict_old_images is called after each build, but only when count > max_images

    # At least the newest image should exist
    exists_2 = await builder._image_exists(images_built[2])
    assert exists_2 is True

    # Cleanup remaining images
    for tag in images_built:
        try:
            await asyncio.create_subprocess_exec(
                "docker", "rmi", tag, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )
        except Exception:
            pass  # Image may already be evicted


@pytest.mark.asyncio
async def test_dockerfile_template_formatting():
    """Test that Dockerfile template is formatted correctly."""
    from fluster.cluster.worker.builder import DOCKERFILE_TEMPLATE

    # Test with no extras
    dockerfile = DOCKERFILE_TEMPLATE.format(base_image="python:3.11-slim", extras_flags="")
    assert "FROM python:3.11-slim" in dockerfile
    assert "ghcr.io/astral-sh/uv:latest" in dockerfile
    assert "UV_CACHE_DIR=/opt/uv-cache" in dockerfile
    assert "--mount=type=cache,target=/opt/uv-cache" in dockerfile

    # Test with extras
    dockerfile = DOCKERFILE_TEMPLATE.format(base_image="python:3.12", extras_flags="--extra dev --extra test")
    assert "FROM python:3.12" in dockerfile
    assert "--extra dev --extra test" in dockerfile
