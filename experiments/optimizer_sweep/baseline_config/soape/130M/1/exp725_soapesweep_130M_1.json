{
  "baseline_config": {
    "beta1": 0.95,
    "beta2": 0.95,
    "block_size": 256,
    "epsilon": 1e-15,
    "learning_rate": 0.008,
    "max_grad_norm": 1.0,
    "min_lr_ratio": 0,
    "partition_grads_into_blocks": true,
    "precondition_frequency": 10,
    "shampoo_beta": 0.95,
    "train_batch_size": 128,
    "warmup": 2000,
    "weight_decay": 0.1
  },
  "model_size": "130m",
  "optimizer_name": "soape",
  "target_chinchilla": 1
}
