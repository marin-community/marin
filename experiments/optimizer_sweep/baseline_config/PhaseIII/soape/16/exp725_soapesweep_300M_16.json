{
  "baseline_config": {
    "beta1": 0.95,
    "beta2": 0.99,
    "block_size": 512,
    "epsilon": 1e-10,
    "learning_rate": 0.004,
    "max_grad_norm": 1,
    "min_lr_ratio": 0,
    "partition_grads_into_blocks": true,
    "precondition_frequency": 10,
    "shampoo_beta": 0.9,
    "train_batch_size": 256,
    "warmup": 1000,
    "weight_decay": 0.1
  },
  "model_size": "300m",
  "optimizer_name": "soape",
  "target_chinchilla": 16
}