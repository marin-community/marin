\subsection{Sweeping Results for AdamW}% adamw - 130m on 1x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 130m on 1x Chinchilla Data}
\label{tab:ablation_adamw_130m_on_1x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-20 & 0.008 & 1 & 0 & 128 & 2000 & 0.1 & 3.529 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw5098e9lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-bc5e36}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.539 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw6b5e10lr0.008-wd0.1-minlr0-warmup2000-b10.95--b1de93}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 3.882 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamwae7d4dlr0.008-wd0.1-minlr0-warmup2000-b10.98--df53b1}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.545 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw5a9f1blr0.008-wd0.1-minlr0-warmup2000-b10.9-b-691bb8}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.535 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamwb5ba64lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-77d771}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.529 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw0848aelr0.008-wd0.1-minlr0-warmup2000-b10.9-b-413f11}{5} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.531 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamwca195dlr0.008-wd0.1-minlr0-warmup2000-b10.9-b-1f0e34}{6} \\
-- & -- & 1e-10 & -- & -- & -- & -- & -- & -- & 3.531 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamwb41b46lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-0cf15c}{7} \\
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.550 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw79cde5lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-019ae3}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 3.538 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw5f56aalr0.016-wd0.1-minlr0-warmup2000-b10.9-b-9972d1}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.781 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw73dd8elr0.032-wd0.1-minlr0-warmup2000-b10.9-b-d0f554}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.534 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw3f4574lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-266a88}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.534 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw30a624lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-c09e98}{12} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.611 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw7fa927lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-8cb11e}{13} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 7.452 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw20884flr0.008-wd0.1-minlr0-warmup500-b10.9-b2-819ba9}{14} \\
-- & -- & -- & -- & -- & -- & -- & 1000 & -- & 3.532 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamwe4d6f6lr0.008-wd0.1-minlr0-warmup1000-b10.9-b-d51a10}{15} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.575 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw6afe2alr0.008-wd0.1-minlr0-warmup4000-b10.9-b-cff12f}{16} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 3.545 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamweb4f13lr0.008-wd0-minlr0-warmup2000-b10.9-b20-f7fd96}{17} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.536 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-2B-adamw2f8ed9lr0.008-wd0.2-minlr0-warmup2000-b10.9-b-f4d5cf}{18} \\
\bottomrule
\end{tabular}
\end{table}

% adamw - 130m on 2x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 130m on 2x Chinchilla Data}
\label{tab:ablation_adamw_130m_on_2x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-20 & 0.008 & 1 & 0 & 128 & 2000 & 0.1 & 3.409 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw90f5c1lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-67adb6}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.417 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw995582lr0.008-wd0.1-minlr0-warmup2000-b10.95--0fb321}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 7.557 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw220e11lr0.008-wd0.1-minlr0-warmup2000-b10.98--f8f851}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.423 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw757bfblr0.008-wd0.1-minlr0-warmup2000-b10.9-b-da391a}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.413 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamwc562dclr0.008-wd0.1-minlr0-warmup2000-b10.9-b-9752b5}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.409 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw0da527lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-9c6463}{5} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.409 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw4f03a8lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-c453b4}{6} \\
-- & -- & 1e-10 & -- & -- & -- & -- & -- & -- & 3.410 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamwf4cc20lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-c52587}{7} \\
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.420 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw8cf61clr0.004-wd0.1-minlr0-warmup2000-b10.9-b-481a17}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 3.419 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw093957lr0.016-wd0.1-minlr0-warmup2000-b10.9-b-d1d1c5}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.840 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw0d117blr0.032-wd0.1-minlr0-warmup2000-b10.9-b-180de6}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.410 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw535ddelr0.008-wd0.1-minlr0-warmup2000-b10.9-b-6c9703}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.408 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw80c699lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-6682a7}{12} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.437 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw5098e9lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-b203b1}{13} \\
-- & -- & -- & -- & -- & -- & 512 & -- & -- & 3.527 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw7fa927lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-23a9e4}{14} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 7.277 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamwb0eee1lr0.008-wd0.1-minlr0-warmup500-b10.9-b2-f92a87}{15} \\
-- & -- & -- & -- & -- & -- & -- & 1000 & -- & 3.413 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamwdb2f8blr0.008-wd0.1-minlr0-warmup1000-b10.9-b-a48171}{16} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.415 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw0cd0aalr0.008-wd0.1-minlr0-warmup4000-b10.9-b-26dd75}{17} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 3.436 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw7a3359lr0.008-wd0-minlr0-warmup2000-b10.9-b20-bf7e74}{18} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.415 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-5B-adamw1d5bddlr0.008-wd0.2-minlr0-warmup2000-b10.9-b-a991d6}{19} \\
\bottomrule
\end{tabular}
\end{table}

% adamw - 130m on 4x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 130m on 4x Chinchilla Data}
\label{tab:ablation_adamw_130m_on_4x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-20 & 0.008 & 1 & 0 & 128 & 2000 & 0.1 & 3.322 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw28a1ddlr0.008-wd0.1-minlr0-warmup2000-b10.9--a5a31c}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.330 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw3cefb4lr0.008-wd0.1-minlr0-warmup2000-b10.95-d2de07}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 3.416 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwdec095lr0.008-wd0.1-minlr0-warmup2000-b10.98-5164f7}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.338 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw50c768lr0.008-wd0.1-minlr0-warmup2000-b10.9--374622}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.329 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw41da7flr0.008-wd0.1-minlr0-warmup2000-b10.9--e79638}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.322 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw11bb27lr0.008-wd0.1-minlr0-warmup2000-b10.9--112190}{5} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.323 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw2151b5lr0.008-wd0.1-minlr0-warmup2000-b10.9--8b96e9}{6} \\
-- & -- & 1e-10 & -- & -- & -- & -- & -- & -- & 3.324 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwc59aaalr0.008-wd0.1-minlr0-warmup2000-b10.9--64f3e7}{7} \\
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.329 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw05a8e1lr0.004-wd0.1-minlr0-warmup2000-b10.9--765ae0}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 3.337 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwdc4f18lr0.016-wd0.1-minlr0-warmup2000-b10.9--5e227e}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.562 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwa3cb44lr0.032-wd0.1-minlr0-warmup2000-b10.9--669760}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.327 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw8a71b5lr0.008-wd0.1-minlr0-warmup2000-b10.9--7e2f5e}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.324 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw2c7533lr0.008-wd0.1-minlr0-warmup2000-b10.9--1aabfe}{12} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.331 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw90f5c1lr0.008-wd0.1-minlr0-warmup2000-b10.9--68bff2}{13} \\
-- & -- & -- & -- & -- & -- & 512 & -- & -- & 3.373 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw5098e9lr0.008-wd0.1-minlr0-warmup2000-b10.9--3dd991}{14} \\
-- & -- & -- & -- & -- & -- & 1024 & -- & -- & 3.480 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw7fa927lr0.008-wd0.1-minlr0-warmup2000-b10.9--5e34ba}{15} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 7.262 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw479b6elr0.008-wd0.1-minlr0-warmup500-b10.9-b-029688}{16} \\
-- & -- & -- & -- & -- & -- & -- & 1000 & -- & 3.327 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwc00703lr0.008-wd0.1-minlr0-warmup1000-b10.9--40ceef}{17} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.325 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamwb9e54alr0.008-wd0.1-minlr0-warmup4000-b10.9--eee94b}{18} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 3.359 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamw76e938lr0.008-wd0-minlr0-warmup2000-b10.9-b2-6ac315}{19} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.335 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-10B-adamweb3777lr0.008-wd0.2-minlr0-warmup2000-b10.9--c002ef}{20} \\
\bottomrule
\end{tabular}
\end{table}

% adamw - 130m on 8x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 130m on 8x Chinchilla Data}
\label{tab:ablation_adamw_130m_on_8x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-20 & 0.008 & 1 & 0 & 256 & 1000 & 0.1 & 3.262 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwc00703lr0.008-wd0.1-minlr0-warmup1000-b10.9--d73c2c}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.273 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwd5d639lr0.008-wd0.1-minlr0-warmup1000-b10.95-658eb8}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 3.430 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw0cb2d6lr0.008-wd0.1-minlr0-warmup1000-b10.98-7c952d}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.272 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwe479a6lr0.008-wd0.1-minlr0-warmup1000-b10.9--7570fe}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.266 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw63b609lr0.008-wd0.1-minlr0-warmup1000-b10.9--2da2b5}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.262 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwc0b69dlr0.008-wd0.1-minlr0-warmup1000-b10.9--2390cc}{5} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw9248c1lr0.008-wd0.1-minlr0-warmup1000-b10.9--7ae1a8}{6} \\
-- & -- & 1e-10 & -- & -- & -- & -- & -- & -- & 3.261 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw357d4clr0.008-wd0.1-minlr0-warmup1000-b10.9--27bdc1}{7} \\
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.270 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwdb2f39lr0.004-wd0.1-minlr0-warmup1000-b10.9--cf39b6}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 7.435 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw06731clr0.016-wd0.1-minlr0-warmup1000-b10.9--2664a6}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.658 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamweac049lr0.032-wd0.1-minlr0-warmup1000-b10.9--cbb38e}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw9268cblr0.008-wd0.1-minlr0-warmup1000-b10.9--c4bf52}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.264 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwf884c5lr0.008-wd0.1-minlr0-warmup1000-b10.9--bf87fc}{12} \\
-- & -- & -- & -- & -- & -- & 128 & -- & -- & 3.264 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw292ad2lr0.008-wd0.1-minlr0-warmup1000-b10.9--b88aa1}{13} \\
-- & -- & -- & -- & -- & -- & 512 & -- & -- & 3.286 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwdb2f8blr0.008-wd0.1-minlr0-warmup1000-b10.9--849bed}{14} \\
-- & -- & -- & -- & -- & -- & 1024 & -- & -- & 3.328 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwe4d6f6lr0.008-wd0.1-minlr0-warmup1000-b10.9--f0487d}{15} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 3.278 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw479b6elr0.008-wd0.1-minlr0-warmup500-b10.9-b-5842d3}{16} \\
-- & -- & -- & -- & -- & -- & -- & 2000 & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw28a1ddlr0.008-wd0.1-minlr0-warmup2000-b10.9--b21aed}{17} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.262 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwb9e54alr0.008-wd0.1-minlr0-warmup4000-b10.9--74889b}{18} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 3.310 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamw549010lr0.008-wd0-minlr0-warmup1000-b10.9-b2-c08f03}{19} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.269 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-21B-adamwe72844lr0.008-wd0.2-minlr0-warmup1000-b10.9--2b5e04}{20} \\
\bottomrule
\end{tabular}
\end{table}

% adamw - 300m on 1x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 300m on 1x Chinchilla Data}
\label{tab:ablation_adamw_300m_on_1x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.008 & 1 & 0 & 128 & 2000 & 0.1 & 3.264 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamwa7aafelr0.008-wd0.1-minlr0-warmup2000-b10.9-b-990eda}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.271 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw55fc1flr0.008-wd0.1-minlr0-warmup2000-b10.95--b7196b}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 7.351 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw3aa56elr0.008-wd0.1-minlr0-warmup2000-b10.98--36a5e7}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.280 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw72a6d2lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-dde1e5}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.269 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw901abclr0.008-wd0.1-minlr0-warmup2000-b10.9-b-de77a3}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.265 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamwfa0d44lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-89eba9}{5} \\
-- & -- & 1e-20 & -- & -- & -- & -- & -- & -- & 3.265 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw057b30lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-cff503}{6} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw863e5alr0.008-wd0.1-minlr0-warmup2000-b10.9-b-8395a7}{7} \\
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.272 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw0c32aelr0.004-wd0.1-minlr0-warmup2000-b10.9-b-a044c7}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 7.760 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw2c8c47lr0.016-wd0.1-minlr0-warmup2000-b10.9-b-689737}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.784 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamwb6e480lr0.032-wd0.1-minlr0-warmup2000-b10.9-b-ff992d}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw418b0elr0.008-wd0.1-minlr0-warmup2000-b10.9-b-e82fe9}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.263 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw4cdb6blr0.008-wd0.1-minlr0-warmup2000-b10.9-b-6bba10}{12} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.282 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw5d409dlr0.008-wd0.1-minlr0-warmup2000-b10.9-b-632ec9}{13} \\
-- & -- & -- & -- & -- & -- & 512 & -- & -- & 3.367 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw2a43e8lr0.008-wd0.1-minlr0-warmup2000-b10.9-b-0d1c6f}{14} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 7.704 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw35a912lr0.008-wd0.1-minlr0-warmup500-b10.9-b2-a0e68a}{15} \\
-- & -- & -- & -- & -- & -- & -- & 1000 & -- & 7.759 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw0c358elr0.008-wd0.1-minlr0-warmup1000-b10.9-b-0be6f6}{16} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.270 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamwea4b29lr0.008-wd0.1-minlr0-warmup4000-b10.9-b-531c85}{17} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 3.303 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamw640457lr0.008-wd0-minlr0-warmup2000-b10.9-b20-12de29}{18} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.275 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-6B-adamwd8feb6lr0.008-wd0.2-minlr0-warmup2000-b10.9-b-ea8bed}{19} \\
\bottomrule
\end{tabular}
\end{table}

% adamw - 520m on 1x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 520m on 1x Chinchilla Data}
\label{tab:ablation_adamw_520m_on_1x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.004 & 1 & 0 & 256 & 1000 & 0.2 & 3.110 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwf7a9c6lr0.004-wd0.2-minlr0-warmup1000-b10.9--0a09ef}{0} \\
\midrule
0.95 & -- & -- & -- & -- & -- & -- & -- & -- & 3.112 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw92fab3lr0.004-wd0.2-minlr0-warmup1000-b10.95-b52d40}{1} \\
0.98 & -- & -- & -- & -- & -- & -- & -- & -- & 3.229 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw757dfblr0.004-wd0.2-minlr0-warmup1000-b10.98-82eb00}{2} \\
-- & 0.9 & -- & -- & -- & -- & -- & -- & -- & 3.116 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw2399bdlr0.004-wd0.2-minlr0-warmup1000-b10.9--235c9f}{3} \\
-- & 0.95 & -- & -- & -- & -- & -- & -- & -- & 3.111 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw49b619lr0.004-wd0.2-minlr0-warmup1000-b10.9--0339de}{4} \\
-- & -- & 1e-25 & -- & -- & -- & -- & -- & -- & 3.116 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwe08492lr0.004-wd0.2-minlr0-warmup1000-b10.9--550b0a}{5} \\
-- & -- & 1e-20 & -- & -- & -- & -- & -- & -- & 3.116 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw920b54lr0.004-wd0.2-minlr0-warmup1000-b10.9--29bc56}{6} \\
-- & -- & 1e-15 & -- & -- & -- & -- & -- & -- & 3.115 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwc8444flr0.004-wd0.2-minlr0-warmup1000-b10.9--ad8761}{7} \\
-- & -- & -- & 0.008 & -- & -- & -- & -- & -- & 7.837 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw6dd5c1lr0.008-wd0.2-minlr0-warmup1000-b10.9--2c3f20}{8} \\
-- & -- & -- & 0.016 & -- & -- & -- & -- & -- & 7.756 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwd13956lr0.016-wd0.2-minlr0-warmup1000-b10.9--db0248}{9} \\
-- & -- & -- & 0.032 & -- & -- & -- & -- & -- & 7.680 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwd5cf15lr0.032-wd0.2-minlr0-warmup1000-b10.9--ef01e7}{10} \\
-- & -- & -- & -- & 0 & -- & -- & -- & -- & 3.114 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw83ff1flr0.004-wd0.2-minlr0-warmup1000-b10.9--2b2992}{11} \\
-- & -- & -- & -- & 2.0 & -- & -- & -- & -- & 3.118 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwc35658lr0.004-wd0.2-minlr0-warmup1000-b10.9--e10d12}{12} \\
-- & -- & -- & -- & -- & -- & 128 & -- & -- & 7.630 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw9d215dlr0.004-wd0.2-minlr0-warmup1000-b10.9--0e6642}{13} \\
-- & -- & -- & -- & -- & -- & 512 & -- & -- & 3.169 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwa3b31flr0.004-wd0.2-minlr0-warmup1000-b10.9--3d3c5b}{14} \\
-- & -- & -- & -- & -- & -- & 1024 & -- & -- & 3.302 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwa78593lr0.004-wd0.2-minlr0-warmup1000-b10.9--f6c234}{15} \\
-- & -- & -- & -- & -- & -- & -- & 500 & -- & 3.165 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamwfa4107lr0.004-wd0.2-minlr0-warmup500-b10.9-b-da6d10}{16} \\
-- & -- & -- & -- & -- & -- & -- & 2000 & -- & 3.113 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw78783dlr0.004-wd0.2-minlr0-warmup2000-b10.9--07b41c}{17} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.126 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw27eccflr0.004-wd0.2-minlr0-warmup4000-b10.9--46c4f0}{18} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0 & 7.270 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw25a778lr0.004-wd0-minlr0-warmup1000-b10.9-b2-f5ae68}{19} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.1 & 3.135 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-10B-adamw1872fclr0.004-wd0.1-minlr0-warmup1000-b10.9--34d388}{20} \\
\bottomrule
\end{tabular}
\end{table}

