{
  "runs": [
    {
      "run_related_info": {
        "hardware_config": {
          "device_flops": 275000000000000.0,
          "device_type": "v4-256",
          "num_devices": 128
        },
        "model_config": {
          "activation_function": "silu",
          "attn_backend": null,
          "cross_entropy_block_size": null,
          "flash_attention_block_size": null,
          "gradient_checkpointing": true,
          "hidden_dim": 768,
          "initializer_range": 0.02,
          "intermediate_dim": 2688,
          "layer_norm_epsilon": 1e-05,
          "num_heads": 12,
          "num_kv_heads": 12,
          "num_layers": 12,
          "reference_checkpoint": "meta-llama/Llama-2-7b-hf",
          "rope": {
            "factor": 1.0,
            "theta": 10000
          },
          "scan_layers": true,
          "seq_len": 1024,
          "tie_word_embeddings": false,
          "tokenizer": null,
          "upcast_attn": false,
          "use_bias": false,
          "use_flash_attention": true,
          "use_layer_norm_weight": true
        },
        "num_parameters": 299649024,
        "run_completion_timestamp": "2025-04-30 10:51:52 UTC",
        "tokenized_dataset": "gs://marin-us-central2/tokenized/fineweb-edu-24698d",
        "total_tokens": 3145728000,
        "train_config": {
          "allow_partial_checkpoint": false,
          "beta1": null,
          "beta2": null,
          "cycle_length": null,
          "data_seed": null,
          "decay": null,
          "ema_beta": null,
          "epsilon": null,
          "initialize_from_checkpoint_path": null,
          "initialize_from_hf": null,
          "int8": false,
          "learning_rate": 0.003,
          "lr_schedule": null,
          "max_grad_norm": null,
          "min_lr_ratio": null,
          "num_train_steps": 3000,
          "optimizer_config": null,
          "per_device_eval_parallelism": null,
          "reset_data_loader_on_init": true,
          "resources": {
            "node_count": 1,
            "runtime_env": {},
            "tpu_type": "v4-256"
          },
          "rewarmup": null,
          "steps_per_eval": 1000,
          "steps_per_export": 10000,
          "steps_per_hf_export": null,
          "steps_per_task_eval": null,
          "train_batch_size": 1024,
          "warmup": null,
          "watch": {
            "include_histograms": false,
            "include_norms": true,
            "include_per_parameter_norms": true,
            "interval": 10,
            "split_scan_layers": true,
            "watch_targets": [
              "grads",
              "params"
            ]
          },
          "weight_decay": 0.1,
          "z_loss_weight": null
        },
        "wandb_run_link": "https://wandb.ai/marin-community/marin/runs/300M_llama-7e3b0f"
      },
      "run_stats": {
        "eval/paloma/c4_en/bpb": 1.1648558378219604,
        "pre_run_flops_estimate": 5.655685949816832e+18,
        "total_training_flops": 3.7885734516607734e+18,
        "training_time_in_minutes": 107.62992760399925
      }
    }
  ]
}
