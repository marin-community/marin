{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from marin.rl.curriculum import (\n",
    "    Curriculum,\n",
    "    CurriculumConfig,\n",
    "    LessonConfig,\n",
    "    LessonDependency,\n",
    ")\n",
    "from marin.rl.environments.base import EnvConfig\n",
    "from marin.rl.types import RolloutStats\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures and Simulation Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CurriculumHistory:\n",
    "    \"\"\"Track curriculum state over time for visualization.\"\"\"\n",
    "\n",
    "    steps: list[int] = field(default_factory=list)\n",
    "    lesson_states: dict[str, list[str]] = field(default_factory=dict)  # lesson_id -> [state1, state2, ...]\n",
    "    sampling_weights: dict[str, list[float]] = field(default_factory=dict)  # lesson_id -> [weight1, weight2, ...]\n",
    "    success_rates: dict[str, list[float]] = field(default_factory=dict)  # lesson_id -> [rate1, rate2, ...]\n",
    "    eval_success_rates: dict[str, list[float]] = field(default_factory=dict)\n",
    "    sample_counts: dict[str, list[int]] = field(default_factory=dict)\n",
    "    metrics: dict[str, list[float]] = field(default_factory=dict)  # metric_name -> [value1, value2, ...]\n",
    "    events: list[dict] = field(default_factory=list)  # [{step, type, lesson_id, details}, ...]\n",
    "\n",
    "\n",
    "def flat_rewards(base_reward: float = 0.8, noise_std: float = 0.01):\n",
    "    \"\"\"Generate flat rewards with minimal noise (should plateau quickly).\"\"\"\n",
    "    def gen(step: int) -> float:\n",
    "        return base_reward + np.random.default_rng().normal(0, noise_std)\n",
    "    return gen\n",
    "\n",
    "\n",
    "def improving_rewards(start: float = 0.1, end: float = 0.9, num_steps: int = 500):\n",
    "    \"\"\"Generate linearly improving rewards (should not plateau until end).\"\"\"\n",
    "    def gen(step: int) -> float:\n",
    "        progress = min(step / num_steps, 1.0)\n",
    "        base = start + (end - start) * progress\n",
    "        return base + np.random.default_rng().normal(0, 0.02)\n",
    "    return gen\n",
    "\n",
    "\n",
    "def noisy_stable_rewards(base_reward: float = 0.5, noise_std: float = 0.05):\n",
    "    \"\"\"Generate noisy but statistically stable rewards (should plateau).\"\"\"\n",
    "    def gen(step: int) -> float:\n",
    "        return base_reward + np.random.default_rng().normal(0, noise_std)\n",
    "    return gen\n",
    "\n",
    "\n",
    "def sigmoid_rewards(midpoint: int = 250, steepness: float = 0.02, start: float = 0.2, end: float = 0.9):\n",
    "    \"\"\"Generate sigmoid improvement curve (plateaus after reaching end).\"\"\"\n",
    "    def gen(step: int) -> float:\n",
    "        x = (step - midpoint) * steepness\n",
    "        sigmoid = 1 / (1 + np.exp(-x))\n",
    "        base = start + (end - start) * sigmoid\n",
    "        return base + np.random.default_rng().normal(0, 0.01)\n",
    "    return gen\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_curriculum_run(config: CurriculumConfig, num_steps: int = 1000, seed: int = 42) -> CurriculumHistory:\n",
    "    \"\"\"Simulate a curriculum run with synthetic rollout data.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    curriculum = Curriculum(config)\n",
    "    history = CurriculumHistory()\n",
    "\n",
    "    # Initialize tracking for each lesson\n",
    "    for lesson_id in config.lessons:\n",
    "        history.lesson_states[lesson_id] = []\n",
    "        history.sampling_weights[lesson_id] = []\n",
    "        history.success_rates[lesson_id] = []\n",
    "        history.eval_success_rates[lesson_id] = []\n",
    "        history.sample_counts[lesson_id] = []\n",
    "\n",
    "    # Define reward patterns for different lessons (for simulation)\n",
    "    reward_patterns = {\n",
    "        \"easy\": flat_rewards(base_reward=0.85),\n",
    "        \"medium\": sigmoid_rewards(midpoint=200, start=0.3, end=0.75),\n",
    "        \"hard\": improving_rewards(start=0.1, end=0.6, num_steps=800),\n",
    "        \"intermediate\": sigmoid_rewards(midpoint=400, start=0.2, end=0.65),\n",
    "        \"advanced\": improving_rewards(start=0.05, end=0.5, num_steps=1000),\n",
    "    }\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        curriculum.current_step = step\n",
    "\n",
    "        # Update unlocked and graduated lessons\n",
    "        prev_unlocked = set(curriculum.unlocked)\n",
    "        prev_graduated = set(curriculum.graduated)\n",
    "\n",
    "        curriculum.update_lessons()\n",
    "\n",
    "        # Record unlock events\n",
    "        new_unlocked = curriculum.unlocked - prev_unlocked\n",
    "        for lesson_id in new_unlocked:\n",
    "            history.events.append(\n",
    "                {\"step\": step, \"type\": \"unlock\", \"lesson_id\": lesson_id, \"details\": \"Dependencies satisfied\"}\n",
    "            )\n",
    "\n",
    "        # Record graduation events\n",
    "        new_graduated = curriculum.graduated - prev_graduated\n",
    "        for lesson_id in new_graduated:\n",
    "            from marin.rl.curriculum import compute_success_ratio, is_plateaued\n",
    "            stats = curriculum.stats[lesson_id]\n",
    "            history.events.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"type\": \"graduate\",\n",
    "                    \"lesson_id\": lesson_id,\n",
    "                    \"details\": {\n",
    "                        \"success_rate\": compute_success_ratio(stats, step),\n",
    "                        \"plateaued\": is_plateaued(stats),\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Sample from curriculum and generate synthetic rollout\n",
    "        if curriculum.unlocked and not all(lid in curriculum.graduated for lid in curriculum.unlocked):\n",
    "            lesson_id = curriculum.sample_lesson(prng_seed=step)\n",
    "\n",
    "            # Generate synthetic reward based on pattern\n",
    "            reward_gen = reward_patterns.get(lesson_id, flat_rewards(0.5))\n",
    "            reward = np.clip(reward_gen(step), 0.0, 1.0)\n",
    "\n",
    "            # Update curriculum stats\n",
    "            rollout_stats = RolloutStats(lesson_id=lesson_id, episode_reward=reward, env_example_id=f\"ex_{step}\")\n",
    "            curriculum.update_lesson_stats([rollout_stats], mode=\"training\")\n",
    "\n",
    "            # Periodic evaluation\n",
    "            if step % config.eval_frequency == 0 and step > 0:\n",
    "                for eval_lesson_id in curriculum.unlocked:\n",
    "                    if eval_lesson_id not in curriculum.graduated:\n",
    "                        # Simulate evaluation (slightly higher performance than training)\n",
    "                        eval_gen = reward_patterns.get(eval_lesson_id, flat_rewards(0.5))\n",
    "                        eval_rewards = [\n",
    "                            np.clip(eval_gen(step) + rng.normal(0, 0.02), 0.0, 1.0)\n",
    "                            for _ in range(config.eval_n_examples)\n",
    "                        ]\n",
    "                        for eval_reward in eval_rewards:\n",
    "                            eval_stats = RolloutStats(\n",
    "                                lesson_id=eval_lesson_id,\n",
    "                                episode_reward=eval_reward,\n",
    "                                env_example_id=f\"eval_{step}\",\n",
    "                            )\n",
    "                            curriculum.update_lesson_stats([eval_stats], mode=\"eval\")\n",
    "\n",
    "        # Record state\n",
    "        history.steps.append(step)\n",
    "        weights = curriculum.compute_sampling_weights()\n",
    "\n",
    "        for lesson_id in config.lessons:\n",
    "            # Determine state\n",
    "            if lesson_id in curriculum.graduated:\n",
    "                state = \"graduated\"\n",
    "            elif lesson_id in curriculum.unlocked:\n",
    "                state = \"active\"\n",
    "            else:\n",
    "                state = \"locked\"\n",
    "\n",
    "            history.lesson_states[lesson_id].append(state)\n",
    "            history.sampling_weights[lesson_id].append(weights.get(lesson_id, 0.0))\n",
    "\n",
    "            stats = curriculum.stats[lesson_id]\n",
    "            history.success_rates[lesson_id].append(stats.training_stats.smoothed_success)\n",
    "            history.eval_success_rates[lesson_id].append(\n",
    "                stats.eval_stats.smoothed_success if stats.eval_stats.last_update_step >= 0 else np.nan\n",
    "            )\n",
    "            history.sample_counts[lesson_id].append(stats.training_stats.total_samples)\n",
    "\n",
    "        # Record curriculum-level metrics\n",
    "        curriculum_metrics = curriculum.get_metrics()\n",
    "        for key in [\"sampling_entropy\", \"effective_lessons\", \"mean_success\"]:\n",
    "            if key not in history.metrics:\n",
    "                history.metrics[key] = []\n",
    "            history.metrics[key].append(curriculum_metrics[key])\n",
    "\n",
    "    return history\n",
    "\n",
    "print(\"✓ Simulation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create Curriculum Configuration\n",
    "\n",
    "Define a 5-lesson curriculum with dependencies:\n",
    "- **easy** → unlocked from start\n",
    "- **medium** → requires 50% on easy\n",
    "- **intermediate** → requires 60% on easy\n",
    "- **hard** → requires 60% on medium\n",
    "- **advanced** → requires 70% on medium AND 65% on intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lessons = {\n",
    "    \"easy\": LessonConfig(\n",
    "        lesson_id=\"easy\",\n",
    "        env_config=EnvConfig(env_class=\"marin.rl.environments.mock_env.MockEnv\", env_args={\"task_type\": \"cats\"}),\n",
    "        stop_threshold=0.9,\n",
    "    ),\n",
    "    \"medium\": LessonConfig(\n",
    "        lesson_id=\"medium\",\n",
    "        env_config=EnvConfig(\n",
    "            env_class=\"marin.rl.environments.mock_env.MockEnv\", env_args={\"task_type\": \"addition\"}\n",
    "        ),\n",
    "        dependencies=[LessonDependency(dependency_id=\"easy\", reward_threshold=0.5)],\n",
    "        stop_threshold=0.85,\n",
    "    ),\n",
    "    \"hard\": LessonConfig(\n",
    "        lesson_id=\"hard\",\n",
    "        env_config=EnvConfig(\n",
    "            env_class=\"marin.rl.environments.mock_env.MockEnv\", env_args={\"task_type\": \"opposites\"}\n",
    "        ),\n",
    "        dependencies=[LessonDependency(dependency_id=\"medium\", reward_threshold=0.6)],\n",
    "        stop_threshold=0.75,\n",
    "    ),\n",
    "    \"intermediate\": LessonConfig(\n",
    "        lesson_id=\"intermediate\",\n",
    "        env_config=EnvConfig(\n",
    "            env_class=\"marin.rl.environments.mock_env.MockEnv\", env_args={\"task_type\": \"number_comparison\"}\n",
    "        ),\n",
    "        dependencies=[LessonDependency(dependency_id=\"easy\", reward_threshold=0.6)],\n",
    "        stop_threshold=0.8,\n",
    "    ),\n",
    "    \"advanced\": LessonConfig(\n",
    "        lesson_id=\"advanced\",\n",
    "        env_config=EnvConfig(\n",
    "            env_class=\"marin.rl.environments.mock_env.MockEnv\", env_args={\"task_type\": \"opposites\"}\n",
    "        ),\n",
    "        dependencies=[\n",
    "            LessonDependency(dependency_id=\"medium\", reward_threshold=0.7),\n",
    "            LessonDependency(dependency_id=\"intermediate\", reward_threshold=0.65),\n",
    "        ],\n",
    "        stop_threshold=0.7,\n",
    "    ),\n",
    "}\n",
    "\n",
    "config = CurriculumConfig(\n",
    "    lessons=lessons,\n",
    "    eval_frequency=100,\n",
    "    eval_n_examples=32,\n",
    "    eval_n_generations=1,\n",
    "    temperature=1.0,\n",
    "    minimum_sample_probability=0.01,\n",
    ")\n",
    "\n",
    "print(\"✓ Curriculum configured with 5 lessons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Plateau Detection\n",
    "\n",
    "Shows how the plateau detection algorithm works with 4 different reward patterns:\n",
    "- **Flat**: Stable rewards trigger plateau quickly\n",
    "- **Improving**: Linear improvement prevents plateau\n",
    "- **Noisy Stable**: Plateau despite variance\n",
    "- **Sigmoid**: Eventually plateaus after curve flattens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marin.rl.curriculum import is_plateaued, LessonStats, PerformanceStats\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle(\"Plateau Detection Examples (Conservative Algorithm)\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "patterns = [\n",
    "    (\"Flat Rewards (Plateaus)\", flat_rewards(0.8, 0.01)),\n",
    "    (\"Improving Rewards (No Plateau)\", improving_rewards(0.1, 0.9, 300)),\n",
    "    (\"Noisy Stable (Plateaus)\", noisy_stable_rewards(0.5, 0.05)),\n",
    "    (\"Sigmoid (Eventually Plateaus)\", sigmoid_rewards(150, 0.02, 0.2, 0.85)),\n",
    "]\n",
    "\n",
    "window = 50\n",
    "threshold = 0.01\n",
    "\n",
    "for ax, (title, gen) in zip(axes.flat, patterns, strict=False):\n",
    "    # Generate reward sequence\n",
    "    steps = 300\n",
    "    rewards = [gen(i) for i in range(steps)]\n",
    "\n",
    "    # Track plateau status using actual curriculum algorithm\n",
    "    plateau_status = []\n",
    "    for i in range(steps):\n",
    "        if i < window:\n",
    "            plateau_status.append(False)\n",
    "        else:\n",
    "            # Use the actual is_plateaued function from curriculum\n",
    "            recent_history = rewards[i - window : i]\n",
    "            stats = LessonStats(training_stats=PerformanceStats(reward_history=recent_history))\n",
    "            plateau_status.append(is_plateaued(stats, window=window, threshold=threshold))\n",
    "\n",
    "    # Plot rewards\n",
    "    ax.plot(rewards, label=\"Rewards\", alpha=0.7, linewidth=1.5)\n",
    "\n",
    "    # Shade plateau regions\n",
    "    plateau_regions = np.array(plateau_status)\n",
    "    ax.fill_between(\n",
    "        range(steps), 0, 1, where=plateau_regions, alpha=0.2, color=\"green\", label=\"Plateaued\", step=\"mid\"\n",
    "    )\n",
    "\n",
    "    # Add linear regression for last window\n",
    "    if len(rewards) >= window:\n",
    "        from scipy import stats as scipy_stats\n",
    "        recent = np.array(rewards[-window:])\n",
    "        x = np.arange(len(recent))\n",
    "        result = scipy_stats.linregress(x, recent)\n",
    "        trend_line = result.slope * x + result.intercept\n",
    "        start_idx = len(rewards) - window\n",
    "        ax.plot(range(start_idx, len(rewards)), trend_line, \"r--\", label=\"Recent Trend\", linewidth=2)\n",
    "\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Reward\")\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation\n",
    "\n",
    "Simulate 1000 training steps with synthetic rewards to generate data for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running simulation...\")\n",
    "history = simulate_curriculum_run(config, num_steps=1000, seed=42)\n",
    "print(f\"✓ Simulation complete ({len(history.steps)} steps)\")\n",
    "print(f\"  Events recorded: {len(history.events)}\")\n",
    "print(f\"  Unlock events: {sum(1 for e in history.events if e['type'] == 'unlock')}\")\n",
    "print(f\"  Graduation events: {sum(1 for e in history.events if e['type'] == 'graduate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Sampling Weights Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "steps = np.array(history.steps)\n",
    "lesson_ids = list(history.sampling_weights.keys())\n",
    "\n",
    "# Plot each lesson's weight as a line (clearer than stacked area)\n",
    "for lesson_id in lesson_ids:\n",
    "    weights = history.sampling_weights[lesson_id]\n",
    "    ax.plot(steps, weights, label=lesson_id, linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_title(\"Sampling Weight Distribution Over Time\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Training Step\")\n",
    "ax.set_ylabel(\"Sampling Probability\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Lesson Lifecycle Timeline\n",
    "\n",
    "Gantt chart showing lesson state transitions:\n",
    "- **Gray**: Locked (dependencies not met)\n",
    "- **Green**: Active (unlocked and sampling)\n",
    "- **Blue**: Graduated (mastered)\n",
    "\n",
    "Events:\n",
    "- **Gold diamonds**: Unlock events\n",
    "- **Blue squares**: Graduation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "lesson_ids = list(history.lesson_states.keys())\n",
    "state_colors = {\"locked\": \"#cccccc\", \"active\": \"#90EE90\", \"graduated\": \"#87CEEB\"}\n",
    "\n",
    "y_pos = {lid: i for i, lid in enumerate(lesson_ids)}\n",
    "\n",
    "# Plot state regions\n",
    "for lesson_id in lesson_ids:\n",
    "    states = history.lesson_states[lesson_id]\n",
    "    current_state = None\n",
    "    start_idx = 0\n",
    "\n",
    "    for idx, state in enumerate([*states, None]):  # Add None to trigger final segment\n",
    "        if state != current_state:\n",
    "            if current_state is not None:\n",
    "                # Draw rectangle for previous state\n",
    "                color = state_colors[current_state]\n",
    "                ax.barh(\n",
    "                    y_pos[lesson_id],\n",
    "                    idx - start_idx,\n",
    "                    left=history.steps[start_idx],\n",
    "                    height=0.8,\n",
    "                    color=color,\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                )\n",
    "            current_state = state\n",
    "            start_idx = idx\n",
    "\n",
    "# Mark events\n",
    "for event in history.events:\n",
    "    lesson_id = event[\"lesson_id\"]\n",
    "    step = event[\"step\"]\n",
    "    event_type = event[\"type\"]\n",
    "\n",
    "    marker = \"D\" if event_type == \"unlock\" else \"s\"\n",
    "    color = \"gold\" if event_type == \"unlock\" else \"blue\"\n",
    "    ax.scatter(step, y_pos[lesson_id], marker=marker, s=100, color=color, edgecolor=\"black\", zorder=10)\n",
    "\n",
    "ax.set_yticks(range(len(lesson_ids)))\n",
    "ax.set_yticklabels(lesson_ids)\n",
    "ax.set_xlabel(\"Training Step\")\n",
    "ax.set_title(\"Lesson Lifecycle Timeline\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(alpha=0.3, axis=\"x\")\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=state_colors[\"locked\"], label=\"Locked\"),\n",
    "    Patch(facecolor=state_colors[\"active\"], label=\"Active\"),\n",
    "    Patch(facecolor=state_colors[\"graduated\"], label=\"Graduated\"),\n",
    "    plt.Line2D([0], [0], marker=\"D\", color=\"w\", markerfacecolor=\"gold\", markersize=10, label=\"Unlock Event\"),\n",
    "    plt.Line2D([0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"blue\", markersize=10, label=\"Graduate Event\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Weight Function\n",
    "\n",
    "**Left**: Base quadratic weight function w = max(0, -4s² + 4s) peaks at 50% success\n",
    "\n",
    "**Right**: Exploration bonus amplifies weights for under-sampled lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Base quadratic weight\n",
    "success_rates = np.linspace(0, 1, 100)\n",
    "base_weights = np.maximum(0, -4 * success_rates**2 + 4 * success_rates)\n",
    "\n",
    "ax1.plot(success_rates, base_weights, linewidth=3, color=\"steelblue\")\n",
    "ax1.axvline(0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Peak at 50%\")\n",
    "ax1.fill_between(success_rates, base_weights, alpha=0.3, color=\"steelblue\")\n",
    "\n",
    "ax1.set_title(\"Base Weight Function\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Success Rate\")\n",
    "ax1.set_ylabel(\"Base Weight\")\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Panel 2: Exploration bonus comparison\n",
    "sample_counts = np.arange(0, 200)\n",
    "exploration_bonus = 1.0 + np.exp(-0.01 * sample_counts)\n",
    "\n",
    "# Show effect on weight for different initial success rates\n",
    "for success_rate in [0.3, 0.5, 0.7]:\n",
    "    base = max(0, -4 * success_rate**2 + 4 * success_rate)\n",
    "    weighted = base * exploration_bonus\n",
    "    ax2.plot(sample_counts, weighted, label=f\"Success={success_rate:.1f}\", linewidth=2)\n",
    "\n",
    "ax2.set_title(\"Exploration Bonus Effect on Weights\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Number of Samples\")\n",
    "ax2.set_ylabel(\"Final Weight\")\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: Health Metrics Dashboard\n",
    "\n",
    "Four key curriculum health indicators:\n",
    "1. **Sampling Entropy**: Diversity measure (low = collapse to single lesson)\n",
    "2. **Effective Lessons**: Inverse Simpson index (how many meaningfully contribute)\n",
    "3. **Mean Success**: Average performance across active lessons\n",
    "4. **Lesson Counts**: Number in each state over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle(\"Curriculum Health Metrics\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "steps = np.array(history.steps)\n",
    "\n",
    "# Panel 1: Sampling entropy\n",
    "ax = axes[0, 0]\n",
    "ax.plot(steps, history.metrics[\"sampling_entropy\"], linewidth=2, color=\"steelblue\")\n",
    "ax.axhline(0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Low diversity threshold\")\n",
    "ax.set_title(\"Sampling Entropy (Diversity)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Entropy\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Panel 2: Effective lessons\n",
    "ax = axes[0, 1]\n",
    "ax.plot(steps, history.metrics[\"effective_lessons\"], linewidth=2, color=\"darkgreen\")\n",
    "ax.axhline(2.0, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Warning threshold\")\n",
    "ax.set_title(\"Effective Lessons (Inverse Simpson)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Effective Count\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Panel 3: Mean success rate\n",
    "ax = axes[1, 0]\n",
    "ax.plot(steps, history.metrics[\"mean_success\"], linewidth=2, color=\"darkorange\")\n",
    "ax.set_title(\"Mean Success Rate (Active Lessons)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Success Rate\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel 4: Lesson counts\n",
    "ax = axes[1, 1]\n",
    "lesson_ids = list(history.lesson_states.keys())\n",
    "\n",
    "locked_count = []\n",
    "active_count = []\n",
    "graduated_count = []\n",
    "\n",
    "for step_idx in range(len(steps)):\n",
    "    locked = sum(1 for lid in lesson_ids if history.lesson_states[lid][step_idx] == \"locked\")\n",
    "    active = sum(1 for lid in lesson_ids if history.lesson_states[lid][step_idx] == \"active\")\n",
    "    graduated = sum(1 for lid in lesson_ids if history.lesson_states[lid][step_idx] == \"graduated\")\n",
    "\n",
    "    locked_count.append(locked)\n",
    "    active_count.append(active)\n",
    "    graduated_count.append(graduated)\n",
    "\n",
    "ax.plot(steps, locked_count, label=\"Locked\", linewidth=2)\n",
    "ax.plot(steps, active_count, label=\"Active\", linewidth=2)\n",
    "ax.plot(steps, graduated_count, label=\"Graduated\", linewidth=2)\n",
    "ax.set_title(\"Lesson State Counts\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
