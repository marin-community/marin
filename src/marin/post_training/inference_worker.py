# Copyright 2025 The Marin Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Inference worker for RL/post-training rollout generation.

This worker loads model checkpoints, generates rollouts from a single environment,
and writes the rollout data to files for training workers to consume.
"""

import logging
import os
import socket
import time
from functools import partial
from pathlib import Path

import jax
import jax.numpy as jnp
from jax.sharding import PartitionSpec as PS
from optax import softmax_cross_entropy_with_integer_labels
from scalax.sharding import MeshShardingHelper, TreePathShardingRule

from .inference import build_sampler
from .load_environments import load_environment_from_spec
from .model_helpers import (
    build_generate_model,
    build_prefill_model,
    llama_config_from_model_config,
    load_tokenizer,
)
from .rl_dataset import create_dataset_from_environment
from .rollout_storage import RolloutBatch, RolloutWriter, TaggedRolloutBatch
from .training_config import TrainingConfig
from .utils import (
    float_to_dtype,
    get_float_dtype_by_name,
    jax_distributed_barrier,
    jax_distributed_initalize,
    load_checkpoint,
)
from .weight_transfer_manager import create_weight_transfer_client

logger = logging.getLogger(__name__)


class InferenceWorker:
    """Asynchonous inference & rollout worker for RL training.

    Inference workers periodically load model checkpoints generated by the training job,
    and continously generate rollouts from a single environment. Rollouts are communicated to the
    training job via a rollout queue.
    """

    _running: bool = True
    training_config: TrainingConfig
    rollout_writer: RolloutWriter

    def __init__(
        self,
        training_config: TrainingConfig,
        environment_spec: str,
        rollout_writer: RolloutWriter,
        rollout_batch_size: int = 32,
        max_rollouts: int | None = None,
        coordinator=None,
    ):
        """Initialize inference worker.

        Args:
            training_config: Training configuration.
            environment_spec: Environment specification string.
            rollout_writer: Writer for rollout output.
            rollout_batch_size: Size of rollout batches.
            max_rollouts: Maximum number of rollouts to generate. None for unlimited.
            coordinator: Coordinator for weight transfer (required for RAY_REMOTING and JAX_TRANSFER_SERVER modes).
        """
        self.training_config = training_config
        self.environment_spec = environment_spec
        self.rollout_batch_size = rollout_batch_size
        self.max_rollouts = max_rollouts
        self.coordinator = coordinator

        jax_distributed_initalize(**self.training_config.distributed.jax_distributed_initialize_config)
        jax_distributed_barrier()

        self.mesh = MeshShardingHelper(
            self.training_config.distributed.inference_sharding,
            ["replica", "fsdp", "sequence", "tensor"],
            mesh_axis_splitting=self.training_config.distributed.physical_axis_splitting,
        )

        with self.mesh.get_context():
            self._setup_components()

        self.rollout_writer = rollout_writer

        # The current model parameters
        self.current_params = None

        # Parameters for the reference (base) model for KL penalties and reference logprobs
        self.reference_params = None

    def stop(self):
        """Stop the inference worker loop."""
        self._running = False

    def _setup_components(self):
        """Setup models, tokenizer, and environment."""
        model_config = self.training_config.model

        llama_config = llama_config_from_model_config(model_config.model_paths, model_config.model_config_override)
        self.prefill_model = build_prefill_model(llama_config, self.training_config)
        self.generate_model = build_generate_model(llama_config, self.training_config)

        self.tokenizer = load_tokenizer(model_config.model_paths, model_config.tokenizer_override)

        self.environment_name = self.environment_spec
        self.environment = load_environment_from_spec(self.environment_spec, self.tokenizer)

        self.max_input_length = self.training_config.hyperparameters.max_input_length
        self.max_output_length = self.training_config.hyperparameters.max_output_length
        self.reference_logprobs_bsize = self.training_config.hyperparameters.reference_logprobs_bsize
        self.pad_token_id = self.training_config.hyperparameters.pad_token_id

        self.inference_params_sharding_rules = TreePathShardingRule(
            *self.prefill_model.config.get_partition_rules(
                model_all_gather_axis=("fsdp", "sequence"),
            )
        )
        self.inference_intermediate_sharding_rules = self.prefill_model.config.get_intermediate_sharding_rules(
            data_axis=("replica", "fsdp"),
            sequence_axis=None,
        )

        self.params_shape = jax.eval_shape(
            lambda: self.prefill_model.init_weights(
                jax.random.PRNGKey(0),
                (
                    self.training_config.hyperparameters.decode_bsize,
                    self.max_input_length + self.max_output_length - 1,
                ),
            )
        )

        self.shard_fns, _ = self.mesh.make_shard_and_gather_fns(self.params_shape, self.inference_params_sharding_rules)

        self._setup_samplers()
        self._compile_functions()

    def _setup_samplers(self):
        """Setup sampling configurations."""
        generation_config = self.training_config.generation_config

        sampler_kwargs = {
            "prefill_model": self.prefill_model,
            "generate_model": self.generate_model,
            "tokenizer": self.tokenizer,
            "bsize": self.training_config.hyperparameters.decode_bsize,
            "prefill_bsize": self.training_config.hyperparameters.prefill_bsize,
            "max_input_length": self.max_input_length,
            "params_sharding_rules": self.inference_params_sharding_rules,
            "intermediate_sharding_rules": self.inference_intermediate_sharding_rules,
            "replica_axis_name": ("replica", "fsdp"),
            "tp_axis_name": "tensor",
            "mesh": self.mesh,
            "pad_token_id": self.pad_token_id,
        }

        self.sampler = build_sampler(generation_config=generation_config, **sampler_kwargs)

    def _compile_functions(self):
        """Compile JAX functions for inference."""  # Get parameter shapes for sharding

        @partial(
            self.mesh.sjit,
            in_shardings=(PS(),),
            out_shardings=self.inference_params_sharding_rules,
            annotation_shardings=self.inference_intermediate_sharding_rules,
        )
        def init_params(rng):
            params = self.prefill_model.init_weights(
                rng,
                (
                    self.training_config.hyperparameters.decode_bsize,
                    self.max_input_length + self.max_output_length - 1,
                ),
            )
            params = float_to_dtype(params, self.training_config.model.inference_param_dtype)
            return params

        @partial(
            self.mesh.sjit,
            in_shardings=(
                self.inference_params_sharding_rules,
                PS(),
                PS(),
                PS(),
                PS(),
            ),
            out_shardings=PS(),
            args_sharding_constraint=(
                self.inference_params_sharding_rules,
                PS(("replica", "fsdp")),
                PS(("replica", "fsdp")),
                PS(("replica", "fsdp")),
                PS(("replica", "fsdp")),
            ),
        )
        def get_logprobs(
            params,
            input_tokens,
            input_attention_mask,
            target_tokens,
            target_attention_mask,
        ):
            full_tokens = jnp.concatenate([input_tokens, target_tokens], axis=1)
            full_attention_mask = jnp.concatenate([input_attention_mask, target_attention_mask], axis=1)
            full_position_ids = jnp.maximum(jnp.cumsum(full_attention_mask, axis=1) - 1, 0)

            logits = self.prefill_model(
                full_tokens[:, :-1],
                full_attention_mask[:, :-1],
                full_position_ids[:, :-1],
                params=params,
                train=False,
            ).logits

            logits = logits[:, input_tokens.shape[1] - 1 :]
            logprobs = -softmax_cross_entropy_with_integer_labels(
                logits.astype(jnp.float32), target_tokens.astype(jnp.int32)
            )
            return logprobs

        self.init_params = init_params
        self.get_logprobs = get_logprobs

    def _find_latest_checkpoint_from_gcs(self) -> str | None:
        """Find the latest checkpoint from the main checkpoint directory for initial loading."""
        # Use the checkpoint directory from weight transfer config for initial loading
        checkpoint_dir = Path(self.training_config.weight_transfer.checkpoint_dir)

        if not checkpoint_dir.exists():
            return None

        # Look for checkpoint directories
        checkpoint_dirs = []
        for item in checkpoint_dir.iterdir():
            if item.is_dir() and item.name.startswith("step_"):
                try:
                    step_num = int(item.name.split("_")[1])
                    checkpoint_dirs.append((step_num, item))
                except (ValueError, IndexError):
                    continue

        if not checkpoint_dirs:
            return None

        # Return path to the latest checkpoint's params.msgpack
        _, latest_dir = max(checkpoint_dirs)
        params_path = latest_dir / "params.msgpack"

        if params_path.exists():
            return str(params_path)

        return None

    def _load_checkpoint(self, checkpoint_path: str):
        """Load model parameters from checkpoint."""
        with self.mesh.get_context():
            logger.info(f"Loading checkpoint from {checkpoint_path}")

            # Load and convert parameters
            params = load_checkpoint(
                checkpoint_path,
                shard_fns=self.shard_fns,
                remove_dict_prefix=self.training_config.model.model_paths.remove_dict_prefix,
                convert_to_dtypes=jax.tree_util.tree_map(
                    lambda x: get_float_dtype_by_name(self.training_config.model.inference_param_dtype),
                    self.params_shape,
                ),
            )
            params = float_to_dtype(params, self.training_config.model.inference_param_dtype)

            logger.info(f"Successfully loaded checkpoint from {checkpoint_path}")
            jax_distributed_barrier()
            return params

    def _load_reference_params(self):
        model_paths = self.training_config.model.model_paths
        if model_paths.params:
            logger.info(f"Found reference checkpoint at {model_paths.params}")
            return self._load_checkpoint(model_paths.params)

        if model_paths.train_state:
            logger.info(f"Found reference checkpoint at {model_paths.train_state}")
            return self._load_checkpoint(model_paths.train_state)

        logger.warning("No checkpoints found, initializing with random weights...")
        return self.init_params(jax.random.PRNGKey(0))

    def _load_model_params(self):
        """Initialize the model from a training checkpoint, initial checkpoint, or randomly."""

        # Try to load from an updated GCS checkpoints first
        latest_checkpoint = self._find_latest_checkpoint_from_gcs()
        if latest_checkpoint is not None:
            logger.info(f"Loading latest checkpoint from GCS at {latest_checkpoint}")
            return self._load_checkpoint(latest_checkpoint)

        return self._load_reference_params()

    def _initialize_weight_transfer(self):
        """Initialize weight transfer manager."""
        # Setup checkpoint directory for weight transfer config
        if not self.training_config.weight_transfer.checkpoint_dir:
            self.training_config.weight_transfer.checkpoint_dir = os.path.join(
                self.training_config.output_dir, "checkpoints"
            )

        self.weight_transfer_client = create_weight_transfer_client(
            config=self.training_config.weight_transfer,
            mesh=self.mesh,
            params_sharding_rules=self.inference_params_sharding_rules,
            shard_fns=self.shard_fns,
            load_checkpoint_fn=self._load_checkpoint,
            coordinator=self.coordinator,
        )

        self.weight_transfer_client.set_params_placeholder(self.current_params)

    def _check_for_new_weights(self):
        """Check for new weights using the weight transfer manager."""
        try:
            jax_distributed_barrier()
            logger.info("Checking for new weights from weight transfer manager...")
            self.current_params, metrics = self.weight_transfer_client.receive_weights(self.current_params)
            jax_distributed_barrier()
            if metrics:
                logger.info(f"Weights updated: {metrics}")
        except Exception as e:
            logger.warning(f"Failed to receive weights: {e}")

    def _generate_rollout_batch(self, rng) -> tuple[list[dict], dict]:
        """Generate a set of rollout batches from the environment."""
        # Create RL dataset from environment
        jax_distributed_barrier()
        logger.info("Current params: %s", type(self.current_params))
        logger.info("Reference params: %s", type(self.reference_params))
        rl_dataset, dataset_metrics = create_dataset_from_environment(
            environment=self.environment,
            sampler=self.sampler,
            params=self.current_params,
            reference_params=self.reference_params,
            get_logprobs_fn=self.get_logprobs,
            n_examples=self.training_config.hyperparameters.n_prompts_per_step,
            n_generations=self.training_config.generation_config.n_generations,
            prng_key=rng,
            reference_logprobs_bsize=self.reference_logprobs_bsize,
            max_input_length=self.max_input_length,
            max_output_length=self.max_output_length,
            pad_token_id=self.pad_token_id,
            tokenizer=self.tokenizer,
            mode="train",
        )
        jax_distributed_barrier()

        return (
            list(rl_dataset.iterate_batches(batch_size=self.rollout_batch_size, shuffle=True, loop=False)),
            dataset_metrics,
        )

    def run(self):
        """Main inference worker loop."""
        logger.info("Starting inference worker...")

        rollouts_generated = 0
        last_checkpoint_check = 0

        self.reference_params = self._load_reference_params()
        self.current_params = self._load_model_params()

        self._initialize_weight_transfer()

        step = 0

        rng = jax.random.PRNGKey(0)

        while self._running:
            jax_distributed_barrier()
            # Check for new weights periodically using weight transfer manager
            current_time = time.time()
            if current_time - last_checkpoint_check >= self.training_config.weight_transfer.poll_interval_seconds:
                self._check_for_new_weights()
                last_checkpoint_check = current_time

            if self.max_rollouts is not None and rollouts_generated >= self.max_rollouts:
                logger.info(f"Reached max rollouts ({self.max_rollouts}), stopping")
                break

            rng, input_rng = jax.random.split(rng)
            rollout_batches, metrics = self._generate_rollout_batch(input_rng)
            for batch_data in rollout_batches:
                step += 1

                if self.training_config.logging.log_freq > 0 and step % self.training_config.logging.log_freq == 0:
                    log_metrics = {"step": step}
                    log_metrics.update(jax.device_get(metrics))
                    log_metrics.update(self.weight_transfer_client.get_metrics())
                    log_metrics = {"inference." + k: v for k, v in log_metrics.items()}
                    logger.info(f"Logging metrics at step {step}... {log_metrics}")

                rollout_batch = TaggedRolloutBatch(
                    batch=RolloutBatch(
                        input_ids=batch_data["input_ids"],
                        attention_mask=batch_data["attention_mask"],
                        position_ids=batch_data["position_ids"],
                        target_ids=batch_data["target_ids"],
                        loss_weights=batch_data["loss_weights"],
                        loss_masks=batch_data["loss_masks"],
                        reference_logprobs=batch_data["reference_logprobs"],
                        policy_logprobs=batch_data["policy_logprobs"],
                    ),
                    env_name=self.environment_name,
                    worker_id=f"{socket.gethostname()}_{os.getpid()}",
                    timestamp=time.time(),
                    rollout_id=f"{socket.gethostname()}_{int(time.time() * 1000000)}_{step}",
                )
                self.rollout_writer.write_batch(rollout_batch)
                rollouts_generated += 1
            logger.info(f"Generating rollout batch {rollouts_generated}")

        self.weight_transfer_client.cleanup()
        logger.info(f"Inference worker completed after generating {rollouts_generated} rollouts")
        jax_distributed_barrier()
